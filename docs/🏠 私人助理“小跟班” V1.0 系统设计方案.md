# 🏠 私人助理“小跟班” V1.0 系统设计方案
---
## 1\. 系统概述
本方案旨在树莓派 4B 硬件平台上，构建一套具备**极低延迟、模块化可插拔、且兼顾隐私与智能**的私人助理系统。系统采用“本地感知+云端大脑”的混合架构，确保核心响应速度。

---
## 2\. 硬件拓扑
* **计算核心**：Raspberry Pi 4B (建议 4G/8G 内存)。
* **输入设备**：USB 免驱麦克风或 ReSpeaker 扩展板（已就位）。
* **输出设备**：3.5mm 音频口小喇叭或 USB 扬声器（已就位）。
* **网络环境**：稳定 WiFi，需具备访问云端 API 的能力（腾讯云、OpenAI 协议接口、Edge-TTS）。

---
## 3\. 软件架构：语音流水线 (Voice Pipeline)
整个系统由五个核心引擎组成，每个引擎均设计为独立接口，方便后续更换。

### 3.1 监听层 (Perception)
* \*\*唤醒引擎 (Wake Word)\*\*：使用 **openWakeWord**。
* \_策略\_：本地实时监听。支持自定义模型（如“小跟班”），无需联网，确保隐私。
* \*\*活跃检测 (VAD)\*\*：使用 **Silero VAD**。
* \_功能\_：作为系统的“节拍器”。唤醒后自动开始监测人声，检测到停顿（500ms-800ms）后自动切断录音。

### 3.2 转换层 (Understanding)
* \*\*语音转文字 (STT)\*\*：集成 **腾讯云一句话识别**。
* \_逻辑\_：内存缓冲录音 -> 转换为 Base64 字节流 -> 触发云端 API。
* \_优势\_：利用每月 5000 次免费额度，中文识别准确度极高。

### 3.3 决策层 (Cognition)
* \*\*大脑引擎 (LLM)\*\*：采用 **OpenAI 协议兼容接口**。
* \_初级阶段\_：直接透传文字给公有云大模型（推荐 DeepSeek）。
* \_高级阶段\_：封装为 **Agent 架构**，引入 System Prompt 控制人设（“小跟班”）。

### 3.4 表现层 (Synthesis)
* \*\*文字转语音 (TTS)\*\*：首选 \*\*Edge-TTS (云希)\*\*，备选 \*\*火山引擎 (小智)\*\*。
* \_逻辑\_：流式获取音频数据 -> 本地音频驱动（ALSA/PulseAudio）播放。
* \_音色\_：追求“AI小智”风格，确保交互的拟人感。

---
## 4\. 核心流程图设计
1. **待机态**：openWakeWord 持续分析音频流，CPU 占用极低。
2. **唤醒态**：检测到关键词，播放起始提示音，开启 VAD 录音。
3. **上传态**：VAD 判定说话结束，将音频流一次性送往腾讯云 STT。
4. **推理态**：STT 文字传给 LLM。LLM 开启 `stream=True`，边生成文字边送往 TTS。
5. **反馈态**：TTS 播放生成的音频。播放完毕后，系统重新回到待机态或开启“连续对话”窗口。

---
## 5\. 模块化与可扩展性设计
为了满足你后续的 Agent 开发需求，系统预留了以下接口槽位：

|**模块名称**|**插拔方式**|**未来规划**|
| ----- | ----- | ----- |
|**Memory (记忆)**|数组/数据库|增加长期上下文，记住腿哥的偏好。|
|**Tools (工具)**|Function Calling|控制 GPIO 开关、查询树莓派状态、查天气等。|
|**RAG (知识库)**|Vector DB|挂载腿哥的私有技术笔记或项目文档。|
|**Logic (逻辑)**|Plug-in|针对特定指令（如“写代码”）切换更强的大模型。|

---
## 6\. 后续实施建议
1. **环境隔离**：建议使用 `venv` 或 `Docker` 部署，防止 Python 库冲突（尤其是音频驱动相关的 `pyaudio`）。
2. **异步化处理**：由于涉及多次网络请求（STT -> LLM -> TTS），必须采用异步编程（`asyncio`），防止录音过程卡顿。
3. **音频降噪**：在树莓派上，建议在 STT 前置一个简单的软件降噪算法，提升复杂环境下的识别率。

---
腿哥，这份方案逻辑清晰，完全避开了公司业务，是你纯粹的“个人私人助理”蓝图。

**既然方案已出，咱们下一步是针对“唤醒词自定义训练”做个详细调研，还是直接开始讨论具体的 Python 异步代码框架架构？**

